import cv2
import numpy as np
from pathlib import Path
from django.conf import settings
import os
import subprocess
import shutil


class ModelExecutor:
    """ëª¨ë¸ ìœ í˜•ë³„ ì‹¤í–‰ í•¨ìˆ˜ ë§¤í•‘"""
    
    @staticmethod
    def get_executor(model):
        """ëª¨ë¸ì˜ task_typeì— ë”°ë¼ ì ì ˆí•œ executor ë°˜í™˜"""
        task_type = model.task_type
        
        executors = {
            'object_detection': ObjectDetectionExecutor,
            'super_resolution': SuperResolutionExecutor,
            'image_restoration': ImageRestorationExecutor,
            'image_classification': ImageClassificationExecutor,  # ì¶”ê°€
            'segmentation': SegmentationExecutor,  # ì¶”ê°€
        }
        
        executor_class = executors.get(task_type)
        if not executor_class:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‘ì—… ìœ í˜•ì…ë‹ˆë‹¤: {task_type}")
        
        return executor_class(model)


class BaseExecutor:
    """ëª¨ë“  executorì˜ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    def __init__(self, model):
        self.model = model
        self.loaded_model = None
        self.load_model()
    
    def load_model(self):
        """ëª¨ë¸ ë¡œë“œ - í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ êµ¬í˜„"""
        raise NotImplementedError
    
    def apply_frame(self, frame):
        """ë‹¨ì¼ í”„ë ˆì„ ì²˜ë¦¬ - í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ êµ¬í˜„"""
        raise NotImplementedError
    
    def process_video(self, input_path, output_path, progress_callback=None):
        """ë™ì˜ìƒ/ì´ë¯¸ì§€ ì²˜ë¦¬ - ê³µí†µ ë¡œì§"""
        print(f"\n{'='*60}\nğŸ” ì²˜ë¦¬ ì‹œì‘\n{'='*60}")

        # ë¯¸ë””ì–´ íƒ€ì… íŒë³„
        is_image = input_path.lower().endswith((".png", ".jpg", ".jpeg", ".webp"))

        cap = cv2.VideoCapture(input_path)
        if not cap.isOpened():
            raise ValueError(f"íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_path}")

        # ë¯¸ë””ì–´ ì •ë³´ ì¶”ì¶œ
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

        if is_image:
            fps = 1
            total_frames = 1
        else:
            fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        print(f"ğŸ–¼ï¸ í•´ìƒë„: {width}x{height} | FPS: {fps} | ì´ í”„ë ˆì„: {total_frames}")

        # ì¶œë ¥ ì„¤ì •
        out = None
        temp_output = output_path
        annotated_frame = None

        if not is_image:
            temp_output = str(
                Path(output_path).parent / f"temp_{Path(output_path).name}"
            )
            fourcc = cv2.VideoWriter_fourcc(*"mp4v")
            out = cv2.VideoWriter(temp_output, fourcc, fps, (width, height))
            if not out.isOpened():
                cap.release()
                raise ValueError("ì¶œë ¥ VideoWriter ìƒì„± ì‹¤íŒ¨")

        all_applications = []
        application_summary = {}
        total_applications_count = 0
        frame_count = 0

        try:
            print(f"ğŸ”„ ì²˜ë¦¬ ì¤‘...")
            while True:
                ret, frame = cap.read()
                if not ret:
                    break

                # í”„ë ˆì„ ì²˜ë¦¬ (í•˜ìœ„ í´ë˜ìŠ¤ë³„ë¡œ ë‹¤ë¦„)
                result = self.apply_frame(frame)
                
                # result ì²˜ë¦¬ ë°©ì‹ì´ executorë§ˆë‹¤ ë‹¤ë¦„
                if isinstance(result, dict):  # detectionì˜ ê²½ìš°
                    annotated_frame = result.get('frame', frame)
                    applications = result.get('applications', [])
                    
                    if applications:
                        all_applications.append(
                            {"frame": frame_count, "applications": applications}
                        )
                        total_applications_count += len(applications)
                        for det in applications:
                            label = det["label"]
                            application_summary[label] = application_summary.get(label, 0) + 1
                else:  # super_resolution, restorationì˜ ê²½ìš°
                    annotated_frame = result

                if not is_image and out:
                    out.write(annotated_frame)

                frame_count += 1
                if progress_callback and frame_count % 10 == 0:
                    progress = int((frame_count / total_frames) * 80)
                    progress_callback(frame_count, total_frames, progress)

        finally:
            cap.release()
            if out:
                out.release()

        # ìµœì¢… ì €ì¥
        if is_image:
            if annotated_frame is not None:
                cv2.imwrite(output_path, annotated_frame)
                print(f"âœ… ì´ë¯¸ì§€ ê²°ê³¼ ì €ì¥: {output_path}")
            ffmpeg_success = True
        else:
            print(f"\nğŸ¬ ë™ì˜ìƒ ì¬ì¸ì½”ë”© ì¤‘...")
            if progress_callback:
                progress_callback(frame_count, total_frames, 85)
            ffmpeg_success = self.reencode_with_ffmpeg(temp_output, output_path)

            if ffmpeg_success and os.path.exists(temp_output):
                os.remove(temp_output)
            elif not ffmpeg_success:
                print(f"âš ï¸ ffmpeg ì‹¤íŒ¨ - ì›ë³¸ íŒŒì¼ ì‚¬ìš©")
                if os.path.exists(output_path):
                    os.remove(output_path)
                os.rename(temp_output, output_path)

        if progress_callback:
            progress_callback(frame_count, total_frames, 100)

        return {
            "applications": all_applications,
            "total_applications": total_applications_count,
            "summary": application_summary,
        }
    
    def reencode_with_ffmpeg(self, input_path, output_path):
        """ffmpeg ì¬ì¸ì½”ë”©"""
        ffmpeg_path = shutil.which("ffmpeg") or r"C:\ffmpeg\bin\ffmpeg.exe"
        if not os.path.exists(ffmpeg_path):
            return False

        try:
            cmd = [
                ffmpeg_path,
                "-i",
                str(input_path),
                "-c:v",
                "libx264",
                "-preset",
                "fast",
                "-y",
                str(output_path),
            ]
            subprocess.run(cmd, capture_output=True, text=True, timeout=1800)
            return os.path.exists(output_path)
        except:
            return False


class ObjectDetectionExecutor(BaseExecutor):
    """ê°ì²´ íƒì§€ Executor (YOLOv5 + YOLOv8 ì§€ì›)"""
    
    def __init__(self, model):
        self.yolo_version = None  # 'v5' ë˜ëŠ” 'v8'
        super().__init__(model)
    
    def detect_yolo_version(self, model_path):
        """
        YOLO ë²„ì „ ìë™ ê°ì§€
        
        Returns:
            'v5': YOLOv5
            'v8': YOLOv8/v9/v10/v11 (ultralytics)
            'onnx': ONNX íŒŒì¼
        """
        model_path_str = str(model_path).lower()
        
        # 0. ONNX íŒŒì¼ í™•ì¸ (ìµœìš°ì„ )
        if model_path_str.endswith('.onnx'):
            print("ğŸ” ONNX íŒŒì¼ í™•ì¸")
            return 'onnx'
        
        # 1. íŒŒì¼ëª… ê¸°ë°˜ ê°ì§€
        if 'yolov5' in model_path_str or 'yolo5' in model_path_str:
            print("ğŸ” íŒŒì¼ëª…ìœ¼ë¡œ YOLOv5 ê°ì§€")
            return 'v5'
        
        if any(v in model_path_str for v in ['yolov8', 'yolov9', 'yolov10', 'yolo11']):
            print("ğŸ” íŒŒì¼ëª…ìœ¼ë¡œ YOLOv8+ ê°ì§€")
            return 'v8'
        
        # 2. ëª¨ë¸ íŒŒì¼ êµ¬ì¡° ë¶„ì„ (ë” ì •í™•)
        if os.path.exists(model_path):
            try:
                # íŒŒì¼ í—¤ë”ë¡œ ONNX ì²´í¬
                with open(model_path, 'rb') as f:
                    header = f.read(8)
                    # ONNX magic number: 0x08 0x03/0x07 ...
                    if header and header[0] == 0x08:
                        print("âœ… ONNX ë§¤ì§ ë„˜ë²„ í™•ì¸")
                        return 'onnx'
                
                import torch
                print(f"ğŸ” ëª¨ë¸ íŒŒì¼ êµ¬ì¡° ë¶„ì„ ì¤‘: {model_path}")
                
                checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
                
                if isinstance(checkpoint, dict):
                    # YOLOv5 íŠ¹ì§•: 'model' í‚¤ + DetectionModel êµ¬ì¡°
                    if 'model' in checkpoint:
                        model_obj = checkpoint.get('model')
                        # YOLOv5ëŠ” modelì´ ê°ì²´ì´ê³  names ì†ì„±ì„ ê°€ì§
                        if hasattr(model_obj, 'names') or hasattr(model_obj, 'yaml'):
                            print("âœ… ëª¨ë¸ êµ¬ì¡°ë¡œ YOLOv5 í™•ì¸")
                            return 'v5'
                    
                    # YOLOv8 íŠ¹ì§•: 'train_args' ë˜ëŠ” ë‹¤ë¥¸ ultralytics í¬ë§·
                    if 'train_args' in checkpoint or 'date' in checkpoint:
                        print("âœ… ëª¨ë¸ êµ¬ì¡°ë¡œ YOLOv8 í™•ì¸")
                        return 'v8'
            except Exception as e:
                print(f"âš ï¸ ëª¨ë¸ êµ¬ì¡° ë¶„ì„ ì‹¤íŒ¨: {e}")
                error_str = str(e)
                
                # torch.load ì‹¤íŒ¨ = ONNXì¼ ê°€ëŠ¥ì„±
                if 'invalid load key' in error_str or 'UnpicklingError' in error_str:
                    print("âœ… PyTorch ë¡œë“œ ì‹¤íŒ¨ â†’ ONNX íŒŒì¼ë¡œ íŒë‹¨")
                    return 'onnx'
                
                # models.yolo/common ì˜¤ë¥˜ = YOLOv5
                if 'models.yolo' in error_str or 'models.common' in error_str:
                    print("âœ… models.yolo ì˜¤ë¥˜ ê°ì§€ â†’ YOLOv5ë¡œ íŒë‹¨")
                    return 'v5'
        
        # 3. ê¸°ë³¸ê°’: YOLOv8 (ultralyticsê°€ ë” ìµœì‹ )
        print("âš ï¸ ë²„ì „ ê°ì§€ ì‹¤íŒ¨ - ê¸°ë³¸ê°’ YOLOv8 ì‚¬ìš©")
        return 'v8'
    
    def load_model(self):
        """YOLO ëª¨ë¸ ë¡œë“œ"""
        print("\n" + "="*60)
        print("ğŸ”„ YOLO ëª¨ë¸ ë¡œë”© ì‹œì‘")
        print("="*60)
        
        # â­ í†µí•© Modelì˜ sourceì— ë”°ë¼ ë¶„ê¸°
        if self.model.source == 'builtin':
            self._load_builtin_model()
        elif self.model.source == 'upload':
            self._load_upload_model()
        elif self.model.source == 'git':
            self._load_git_model()
        elif self.model.source == 'huggingface':
            self._load_huggingface_model()
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ ì†ŒìŠ¤: {self.model.source}")
        
        print(f"âœ… YOLO{self.yolo_version.upper()} ë¡œë“œ ì™„ë£Œ")
        print("="*60 + "\n")
    
    def _load_builtin_model(self):
        """Built-in ëª¨ë¸ ë¡œë“œ"""
        from ultralytics import YOLO
        
        # YOLOv8 builtinì€ ìë™ ë‹¤ìš´ë¡œë“œ
        self.yolo_version = 'v8'
        
        builtin_dir = settings.DEFAULT_MODELS_DIR
        os.makedirs(builtin_dir, exist_ok=True)
        
        # í”„ë¦¬ì…‹ ì´ë¦„ (ì˜ˆ: yolov8n.pt)
        preset = self.model.builtin_preset
        target_path = os.path.join(builtin_dir, preset)
        
        print(f"ğŸ“¦ Built-in ëª¨ë¸: {preset}")
        
        if os.path.exists(target_path):
            print(f"âœ… ëª¨ë¸ íŒŒì¼ ì¡´ì¬")
            print(f"   ê²½ë¡œ: {target_path}")
            self.loaded_model = YOLO(target_path)
        else:
            print(f"ğŸ“¥ ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {preset}")
            
            # ultralytics í™˜ê²½ë³€ìˆ˜ ì„¤ì •
            original_env = os.environ.get('YOLO_CONFIG_DIR')
            os.environ['YOLO_CONFIG_DIR'] = str(builtin_dir)
            
            try:
                # YOLO ëª¨ë¸ ë¡œë“œ (ìë™ ë‹¤ìš´ë¡œë“œ)
                self.loaded_model = YOLO(preset)
                
                # ë‹¤ìš´ë¡œë“œ í›„ ê²½ë¡œ í™•ì¸ ë° ë³µì‚¬
                possible_paths = [
                    os.path.join(builtin_dir, preset),
                    Path.home() / '.cache' / 'ultralytics' / preset,
                    os.path.join(os.getcwd(), preset),
                ]
                
                downloaded_path = None
                for path in possible_paths:
                    if os.path.exists(path):
                        downloaded_path = path
                        print(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {downloaded_path}")
                        break
                
                # builtin í´ë”ë¡œ ë³µì‚¬
                if downloaded_path and str(downloaded_path) != target_path:
                    print(f"ğŸ“‹ ëª¨ë¸ì„ builtin í´ë”ë¡œ ë³µì‚¬ ì¤‘...")
                    shutil.copy2(str(downloaded_path), target_path)
                    print(f"âœ… ë³µì‚¬ ì™„ë£Œ: {target_path}")
                    
                    # ì›ë³¸ì´ í˜„ì¬ ë””ë ‰í† ë¦¬ì— ìˆìœ¼ë©´ ì‚­ì œ
                    if str(downloaded_path) == os.path.join(os.getcwd(), preset):
                        os.remove(downloaded_path)
                        print(f"ğŸ—‘ï¸ ì„ì‹œ íŒŒì¼ ì‚­ì œ: {downloaded_path}")
                    
                    # DBì— íŒŒì¼ í¬ê¸° ì €ì¥
                    if os.path.exists(target_path):
                        file_size = os.path.getsize(target_path)
                        print(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {file_size / (1024*1024):.2f} MB")
                        
                        if self.model.file_size == 0:
                            self.model.file_size = file_size
                            self.model.save(update_fields=['file_size'])
                            print(f"ğŸ’¾ DB ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            finally:
                # í™˜ê²½ë³€ìˆ˜ ë³µì›
                if original_env:
                    os.environ['YOLO_CONFIG_DIR'] = original_env
                elif 'YOLO_CONFIG_DIR' in os.environ:
                    del os.environ['YOLO_CONFIG_DIR']
    
    def _load_upload_model(self):
        """ì—…ë¡œë“œëœ ëª¨ë¸ ë¡œë“œ"""
        model_path = self.model.model_file.path
        
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_path}")
        
        print(f"ğŸ“ Upload ëª¨ë¸: {os.path.basename(model_path)}")
        print(f"   ê²½ë¡œ: {model_path}")
        
        # YOLO ë²„ì „ ê°ì§€
        self.yolo_version = self.detect_yolo_version(model_path)
        
        # ë²„ì „ë³„ ë¡œë“œ
        if self.yolo_version == 'onnx':
            self._load_onnx(model_path)
        elif self.yolo_version == 'v5':
            self._load_yolov5(model_path)
        else:
            self._load_yolov8(model_path)
    
    def _load_git_model(self):
        """Git ëª¨ë¸ ë¡œë“œ"""
        model_path = self.model.get_model_path()
        
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"Git ëª¨ë¸ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_path}")
        
        print(f"ğŸ“ Git ëª¨ë¸: {model_path}")
        
        # Git ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë¸ íŒŒì¼ ì°¾ê¸° (.pt, .onnx)
        pt_files = list(Path(model_path).rglob("*.pt"))
        onnx_files = list(Path(model_path).rglob("*.onnx"))
        
        # ìš°ì„ ìˆœìœ„: ONNX > PT
        if onnx_files:
            actual_model_path = str(onnx_files[0])
        elif pt_files:
            actual_model_path = str(pt_files[0])
        else:
            raise FileNotFoundError(f"Git ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë¸ íŒŒì¼(.pt, .onnx)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        print(f"   ëª¨ë¸ íŒŒì¼: {actual_model_path}")
        
        # YOLO ë²„ì „ ê°ì§€ ë° ë¡œë“œ
        self.yolo_version = self.detect_yolo_version(actual_model_path)
        
        if self.yolo_version == 'onnx':
            self._load_onnx(actual_model_path)
        elif self.yolo_version == 'v5':
            self._load_yolov5(actual_model_path)
        else:
            self._load_yolov8(actual_model_path)
    
    def _load_huggingface_model(self):
        """HuggingFace ëª¨ë¸ ë¡œë“œ"""
        model_id = self.model.hf_model_id
        
        print(f"ğŸ¤— HuggingFace ëª¨ë¸: {model_id}")
        
        # TODO: HuggingFaceì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
        # ì„ì‹œë¡œ ì—ëŸ¬ ë°œìƒ
        raise NotImplementedError("HuggingFace ëª¨ë¸ ë¡œë“œëŠ” ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    def _load_yolov5(self, model_path):
        """YOLOv5 ëª¨ë¸ ë¡œë“œ"""
        import torch
        import sys
        from pathlib import Path
        
        print(f"ğŸ”„ YOLOv5 ë¡œë”© ì¤‘...")
        
        # YOLOv5 ì €ì¥ì†Œ ê²½ë¡œ
        yolov5_repo = Path(torch.hub.get_dir()) / 'ultralytics_yolov5_master'
        
        if not yolov5_repo.exists():
            print(f"âš ï¸ YOLOv5 ì €ì¥ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œ ì¤‘...")
            # ì €ì¥ì†Œ ë‹¤ìš´ë¡œë“œ
            torch.hub.load('ultralytics/yolov5', 'yolov5s', force_reload=True)
        
        # YOLOv5 ê²½ë¡œë¥¼ sys.pathì— ì¶”ê°€
        yolov5_path = str(yolov5_repo)
        if yolov5_path not in sys.path:
            sys.path.insert(0, yolov5_path)
        
        try:
            # ì§ì ‘ ë¡œì»¬ ê²½ë¡œì—ì„œ ë¡œë“œ
            self.loaded_model = torch.hub.load(
                str(yolov5_repo),
                'custom',
                path=model_path,
                source='local',  # â­ ì¤‘ìš”: localë¡œ ì§€ì •
                force_reload=False
            )
            
            print(f"âœ… YOLOv5 ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âš ï¸ torch.hub.load ì‹¤íŒ¨, ì§ì ‘ ë¡œë“œ ì‹œë„...")
            
            # Plan B: ì§ì ‘ ëª¨ë¸ ë¡œë“œ
            try:
                from models.common import DetectMultiBackend
                from models.experimental import attempt_load
                
                # ì§ì ‘ ë¡œë“œ
                device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
                self.loaded_model = attempt_load(model_path, device=device)
                
                # AutoShape ì ìš© (ì „ì²˜ë¦¬ ìë™í™”)
                from models.common import AutoShape
                self.loaded_model = AutoShape(self.loaded_model)
                
                print(f"âœ… YOLOv5 ì§ì ‘ ë¡œë“œ ì™„ë£Œ")
                
            except Exception as e2:
                print(f"âŒ ì§ì ‘ ë¡œë“œë„ ì‹¤íŒ¨: {e2}")
                raise RuntimeError(
                    f"YOLOv5 ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨.\n"
                    f"torch.hub ì˜¤ë¥˜: {e}\n"
                    f"ì§ì ‘ ë¡œë“œ ì˜¤ë¥˜: {e2}\n"
                    f"YOLOv8 í˜•ì‹(.pt)ì„ ì‚¬ìš©í•˜ê±°ë‚˜ ONNX íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”."
                )
    
    def _load_yolov8(self, model_path):
        """YOLOv8 ëª¨ë¸ ë¡œë“œ"""
        from ultralytics import YOLO
        
        print(f"ğŸ”„ YOLOv8 ë¡œë”© ì¤‘...")
        
        self.loaded_model = YOLO(model_path)
        
        print(f"âœ… YOLOv8 ë¡œë“œ ì™„ë£Œ")
    
    def _load_onnx(self, model_path):
        """ONNX ëª¨ë¸ ë¡œë“œ"""
        try:
            import onnxruntime as ort
        except ImportError:
            raise ImportError(
                "onnxruntimeê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
                "pip install onnxruntime ë˜ëŠ” pip install onnxruntime-gpu ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”."
            )
        
        print(f"ğŸ”„ ONNX ëª¨ë¸ ë¡œë”© ì¤‘...")
        
        # ONNX Runtime ì„¸ì…˜ ìƒì„±
        self.loaded_model = ort.InferenceSession(
            model_path,
            providers=['CPUExecutionProvider']  # GPU: CUDAExecutionProvider
        )
        
        # ì…ë ¥/ì¶œë ¥ ì •ë³´ í™•ì¸
        input_name = self.loaded_model.get_inputs()[0].name
        input_shape = self.loaded_model.get_inputs()[0].shape
        print(f"   ì…ë ¥: {input_name}, Shape: {input_shape}")
        
        output_names = [out.name for out in self.loaded_model.get_outputs()]
        print(f"   ì¶œë ¥: {output_names}")
        
        print(f"âœ… ONNX ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    def apply_frame(self, frame):
        """YOLO ê°ì²´ íƒì§€ (ë²„ì „ë³„ ë¶„ê¸°)"""
        if not self.loaded_model:
            return {'frame': frame, 'applications': []}

        try:
            # 4ì±„ë„(RGBA) -> 3ì±„ë„(BGR) ë³€í™˜
            if len(frame.shape) == 3 and frame.shape[2] == 4:
                frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR)

            # ë²„ì „ë³„ ì¶”ë¡ 
            if self.yolo_version == 'onnx':
                applications = self._apply_onnx(frame)
            elif self.yolo_version == 'v5':
                applications = self._apply_yolov5(frame)
            else:
                applications = self._apply_yolov8(frame)
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            annotated_frame = self.draw_applications(frame, applications)
            
            return {
                'frame': annotated_frame,
                'applications': applications
            }

        except Exception as e:
            print(f"âš ï¸ íƒì§€ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return {'frame': frame, 'applications': []}
    
    def _apply_yolov5(self, frame):
        """YOLOv5 ì¶”ë¡ """
        # BGR -> RGB ë³€í™˜ (YOLOv5 í•„ìš”)
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # ì¶”ë¡ 
        results = self.loaded_model(frame_rgb)
        
        # ê²°ê³¼ íŒŒì‹±
        applications = []
        
        # confidence threshold (ê¸°ë³¸ê°’ 0.25)
        conf_threshold = 0.25
        
        # results.xyxy[0]: [x1, y1, x2, y2, conf, cls]
        for *box, conf, cls in results.xyxy[0].cpu().numpy():
            confidence = float(conf)
            
            if confidence >= conf_threshold:
                x1, y1, x2, y2 = map(int, box)
                class_id = int(cls)
                label = results.names[class_id]
                
                applications.append({
                    'label': label,
                    'confidence': confidence,
                    'bbox': [x1, y1, x2 - x1, y2 - y1],  # [x, y, w, h]
                })
        
        return applications
    
    def _apply_yolov8(self, frame):
        """YOLOv8 ì¶”ë¡ """
        results = self.loaded_model(frame, verbose=False)
        applications = []

        # confidence threshold (ê¸°ë³¸ê°’ 0.25)
        conf_threshold = 0.25

        for result in results:
            for box in result.boxes:
                confidence = float(box.conf[0])
                
                if confidence >= conf_threshold:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    class_id = int(box.cls[0])
                    label = self.loaded_model.names[class_id]

                    applications.append({
                        'label': label,
                        'confidence': confidence,
                        'bbox': [int(x1), int(y1), int(x2 - x1), int(y2 - y1)],
                    })
        
        return applications
    
    def _apply_onnx(self, frame):
        """ONNX ëª¨ë¸ ì¶”ë¡  (YOLOv5/v8 ONNX)"""
        import numpy as np
        
        # ì…ë ¥ ì „ì²˜ë¦¬
        input_name = self.loaded_model.get_inputs()[0].name
        input_shape = self.loaded_model.get_inputs()[0].shape
        
        # ì…ë ¥ í¬ê¸° (ì¼ë°˜ì ìœ¼ë¡œ 640x640)
        input_height = input_shape[2] if len(input_shape) > 2 else 640
        input_width = input_shape[3] if len(input_shape) > 3 else 640
        
        # ì›ë³¸ í”„ë ˆì„ í¬ê¸°
        orig_h, orig_w = frame.shape[:2]
        
        # BGR -> RGB & ë¦¬ì‚¬ì´ì¦ˆ
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frame_resized = cv2.resize(frame_rgb, (input_width, input_height))
        
        # Normalize & Transpose (HWC -> CHW)
        input_tensor = frame_resized.astype(np.float32) / 255.0
        input_tensor = np.transpose(input_tensor, (2, 0, 1))  # HWC -> CHW
        input_tensor = np.expand_dims(input_tensor, axis=0)  # Add batch dimension
        
        # ì¶”ë¡ 
        outputs = self.loaded_model.run(None, {input_name: input_tensor})
        
        # ğŸ” ë””ë²„ê¹…: ì¶œë ¥ í˜•ì‹ í™•ì¸
        print(f"\n{'='*60}")
        print(f"ğŸ” ONNX ì¶œë ¥ ë””ë²„ê¹…")
        print(f"{'='*60}")
        print(f"ì¶œë ¥ ê°œìˆ˜: {len(outputs)}")
        for i, output in enumerate(outputs):
            print(f"outputs[{i}] shape: {output.shape}")
            if i == 0 and len(output.shape) >= 2:
                print(f"  â†’ ì²« ë²ˆì§¸ detection shape: {output[0].shape if output.shape[0] > 0 else 'empty'}")
                if output.shape[0] > 0 and len(output[0]) > 0:
                    print(f"  â†’ ì²« ë²ˆì§¸ ê°’ ìƒ˜í”Œ: {output[0][0][:10]}")  # ì²˜ìŒ 10ê°œ ê°’
        
        # ê²°ê³¼ íŒŒì‹±
        applications = []
        conf_threshold = 0.25
        
        # YOLOv5 ONNX ì¶œë ¥ í˜•ì‹ í™•ì¸
        # ê°€ëŠ¥í•œ í˜•ì‹:
        # 1. (1, 25200, 85) - YOLOv5 í‘œì¤€
        # 2. (1, 84, 8400) - YOLOv8 í˜•ì‹
        # 3. (1, N, 6) - [x1, y1, x2, y2, conf, class]
        
        output = outputs[0]
        
        # í˜•ì‹ 1: (1, 25200, 85) - YOLOv5 í‘œì¤€
        if len(output.shape) == 3 and output.shape[2] > output.shape[1]:
            print(f"âœ… YOLOv5 í‘œì¤€ í˜•ì‹ ê°ì§€: {output.shape}")
            detections = output[0]  # Remove batch dimension
            
            for detection in detections:
                # Confidence
                obj_conf = detection[4]
                
                if obj_conf >= conf_threshold:
                    # Class scores (index 5~)
                    class_scores = detection[5:]
                    class_id = np.argmax(class_scores)
                    class_conf = class_scores[class_id]
                    
                    confidence = obj_conf * class_conf
                    
                    if confidence >= conf_threshold:
                        # Bounding box (ONNXëŠ” ì´ë¯¸ í”½ì…€ ì¢Œí‘œì¼ ìˆ˜ ìˆìŒ)
                        x_center, y_center, width, height = detection[:4]
                        
                        # ìŠ¤ì¼€ì¼ ì¡°ì • (640x640 -> ì›ë³¸ í¬ê¸°)
                        scale_x = orig_w / input_width
                        scale_y = orig_h / input_height
                        
                        x_center *= scale_x
                        y_center *= scale_y
                        width *= scale_x
                        height *= scale_y
                        
                        # Convert to x1, y1, x2, y2
                        x1 = int(x_center - width / 2)
                        y1 = int(y_center - height / 2)
                        x2 = int(x_center + width / 2)
                        y2 = int(y_center + height / 2)
                        
                        # Clamp to frame bounds
                        x1 = max(0, x1)
                        y1 = max(0, y1)
                        x2 = min(orig_w, x2)
                        y2 = min(orig_h, y2)
                        
                        # Get label from model metadata or use class_id
                        if self.model.classes and len(self.model.classes) > class_id:
                            label = self.model.classes[class_id]
                        else:
                            label = f"class_{class_id}"
                        
                        applications.append({
                            'label': label,
                            'confidence': float(confidence),
                            'bbox': [x1, y1, x2 - x1, y2 - y1],
                        })
        
        # í˜•ì‹ 2: (1, 84, 8400) - YOLOv8 í˜•ì‹ (Transpose í•„ìš”)
        elif len(output.shape) == 3 and output.shape[1] < 100:
            print(f"âœ… YOLOv8 í˜•ì‹ ê°ì§€: {output.shape}")
            output = output[0]  # Remove batch (84, 8400)
            output = output.T  # Transpose to (8400, 84)
            
            # [x_center, y_center, width, height, class_probs...]
            for detection in output:
                # Class scores (index 4~)
                class_scores = detection[4:]
                class_id = np.argmax(class_scores)
                confidence = class_scores[class_id]
                
                if confidence >= conf_threshold:
                    # Bounding box
                    x_center, y_center, width, height = detection[:4]
                    
                    # ìŠ¤ì¼€ì¼ ì¡°ì •
                    scale_x = orig_w / input_width
                    scale_y = orig_h / input_height
                    
                    x_center *= scale_x
                    y_center *= scale_y
                    width *= scale_x
                    height *= scale_y
                    
                    # Convert to x1, y1, x2, y2
                    x1 = int(x_center - width / 2)
                    y1 = int(y_center - height / 2)
                    x2 = int(x_center + width / 2)
                    y2 = int(y_center + height / 2)
                    
                    # Clamp
                    x1 = max(0, x1)
                    y1 = max(0, y1)
                    x2 = min(orig_w, x2)
                    y2 = min(orig_h, y2)
                    
                    # Label
                    if self.model.classes and len(self.model.classes) > class_id:
                        label = self.model.classes[class_id]
                    else:
                        label = f"class_{class_id}"
                    
                    applications.append({
                        'label': label,
                        'confidence': float(confidence),
                        'bbox': [x1, y1, x2 - x1, y2 - y1],
                    })
        
        else:
            print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ONNX ì¶œë ¥ í˜•ì‹: {output.shape}")
            print(f"   ìˆ˜ë™ìœ¼ë¡œ íŒŒì‹± ë¡œì§ì„ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.")
        
        print(f"âœ… íƒì§€ëœ ê°ì²´: {len(applications)}ê°œ")
        print(f"{'='*60}\n")
        
        return applications
    
    def draw_applications(self, frame, applications):
        """íƒì§€ ê²°ê³¼ë¥¼ í”„ë ˆì„ì— ê·¸ë¦¬ê¸°"""
        result = frame.copy()
        for det in applications:
            x, y, w, h = det["bbox"]
            label = det["label"]
            conf = det["confidence"]
            color = self.get_color_for_label(label)

            cv2.rectangle(result, (x, y), (x + w, y + h), color, 2)
            text = f"{label} {conf:.2f}"
            cv2.putText(
                result, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2
            )
        return result

    def get_color_for_label(self, label):
        """ë¼ë²¨ë³„ ìƒ‰ìƒ"""
        hash_val = hash(label)
        return (hash_val & 0xFF, (hash_val >> 8) & 0xFF, (hash_val >> 16) & 0xFF)


class SuperResolutionExecutor(BaseExecutor):
    """í•´ìƒë„ ê°œì„  Executor"""
    
    def load_model(self):
        """í•´ìƒë„ ê°œì„  ëª¨ë¸ ë¡œë“œ"""
        print("\n" + "="*60)
        print("ğŸ”„ í•´ìƒë„ ê°œì„  ëª¨ë¸ ë¡œë”© ì‹œì‘")
        print("="*60)
        
        model_path = self.model.get_model_path()
        if not model_path:
            raise ValueError("ëª¨ë¸ íŒŒì¼ì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # TODO: ì‹¤ì œ ëª¨ë¸ ë¡œë“œ êµ¬í˜„
        # ì˜ˆì‹œ: Real-ESRGAN, SRGAN ë“±
        print(f"âš ï¸ í•´ìƒë„ ê°œì„  ëª¨ë¸ ë¡œë“œëŠ” ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        print(f"ëª¨ë¸ ê²½ë¡œ: {model_path}")
        self.loaded_model = None
        
        print("="*60 + "\n")
    
    def apply_frame(self, frame):
        """ì´ë¯¸ì§€ í•´ìƒë„ ê°œì„ """
        if not self.loaded_model:
            # TODO: ì‹¤ì œ êµ¬í˜„
            # ì„ì‹œë¡œ 2ë°° ì—…ìŠ¤ì¼€ì¼ë§
            return cv2.resize(frame, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
        
        # TODO: ì‹¤ì œ ëª¨ë¸ ì¶”ë¡ 
        return frame


class ImageRestorationExecutor(BaseExecutor):
    """ì´ë¯¸ì§€ ë³µì› Executor"""
    
    def load_model(self):
        """ì´ë¯¸ì§€ ë³µì› ëª¨ë¸ ë¡œë“œ"""
        print("\n" + "="*60)
        print("ğŸ”„ ì´ë¯¸ì§€ ë³µì› ëª¨ë¸ ë¡œë”© ì‹œì‘")
        print("="*60)
        
        model_path = self.model.get_model_path()
        if not model_path:
            raise ValueError("ëª¨ë¸ íŒŒì¼ì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # TODO: ì‹¤ì œ ëª¨ë¸ ë¡œë“œ êµ¬í˜„
        # ì˜ˆì‹œ: DeOldify, Bringing Old Photos Back to Life ë“±
        print(f"âš ï¸ ì´ë¯¸ì§€ ë³µì› ëª¨ë¸ ë¡œë“œëŠ” ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        print(f"ëª¨ë¸ ê²½ë¡œ: {model_path}")
        self.loaded_model = None
        
        print("="*60 + "\n")
    
    def apply_frame(self, frame):
        """ì´ë¯¸ì§€ ë³µì›"""
        if not self.loaded_model:
            # TODO: ì‹¤ì œ êµ¬í˜„
            # ì„ì‹œë¡œ ë…¸ì´ì¦ˆ ì œê±°ë§Œ ìˆ˜í–‰
            return cv2.fastNlMeansDenoisingColored(frame, None, 10, 10, 7, 21)
        
        # TODO: ì‹¤ì œ ëª¨ë¸ ì¶”ë¡ 
        return frame


class ImageClassificationExecutor(BaseExecutor):
    """ì´ë¯¸ì§€ ë¶„ë¥˜ Executor (ì¶”í›„ êµ¬í˜„)"""
    
    def load_model(self):
        """ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ"""
        print("\n" + "="*60)
        print("ğŸ”„ ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ ë¡œë”© ì‹œì‘")
        print("="*60)
        print(f"âš ï¸ ì´ë¯¸ì§€ ë¶„ë¥˜ ëª¨ë¸ì€ ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        print(f"ëª¨ë¸: {self.model.name}")
        print("="*60 + "\n")
        raise NotImplementedError("ì´ë¯¸ì§€ ë¶„ë¥˜ ê¸°ëŠ¥ì€ ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. vision_engineì€ í˜„ì¬ ê°ì²´ íƒì§€(object_detection)ë§Œ ì§€ì›í•©ë‹ˆë‹¤.")
    
    def apply_frame(self, frame):
        """ì´ë¯¸ì§€ ë¶„ë¥˜"""
        raise NotImplementedError("ì´ë¯¸ì§€ ë¶„ë¥˜ ê¸°ëŠ¥ì€ ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")


class SegmentationExecutor(BaseExecutor):
    """ì„¸ê·¸ë©˜í…Œì´ì…˜ Executor (ì¶”í›„ êµ¬í˜„)"""
    
    def load_model(self):
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ë¡œë“œ"""
        print("\n" + "="*60)
        print("ğŸ”„ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ë¡œë”© ì‹œì‘")
        print("="*60)
        print(f"âš ï¸ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ì€ ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        print(f"ëª¨ë¸: {self.model.name}")
        print("="*60 + "\n")
        raise NotImplementedError("ì„¸ê·¸ë©˜í…Œì´ì…˜ ê¸°ëŠ¥ì€ ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. vision_engineì€ í˜„ì¬ ê°ì²´ íƒì§€(object_detection)ë§Œ ì§€ì›í•©ë‹ˆë‹¤.")
    
    def apply_frame(self, frame):
        """ì„¸ê·¸ë©˜í…Œì´ì…˜"""
        raise NotImplementedError("ì„¸ê·¸ë©˜í…Œì´ì…˜ ê¸°ëŠ¥ì€ ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")


# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ê¸°ì¡´ í´ë˜ìŠ¤ ìœ ì§€
# class ModelApplier:
#     """ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼ í´ë˜ìŠ¤"""
    
#     def __init__(self, model):
#         self.executor = ModelExecutor.get_executor(model)
#         # ê¸°ì¡´ ì†ì„± ìœ ì§€
#         self.model = model
#         self.yolo_model = getattr(self.executor, 'loaded_model', None)
#         self.model_type = model.task_type
    
#     def process_video(self, input_path, output_path, progress_callback=None):
#         return self.executor.process_video(input_path, output_path, progress_callback)
    
#     def apply_frame(self, frame):
#         result = self.executor.apply_frame(frame)
#         # ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ ë§ì¶”ê¸°
#         if isinstance(result, dict):
#             return result.get('applications', [])
#         return []