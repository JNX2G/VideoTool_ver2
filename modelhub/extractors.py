"""
ëª¨ë¸ íŒŒì¼ì—ì„œ ë©”íƒ€ë°ì´í„° ìë™ ì¶”ì¶œ
"""
import os
from pathlib import Path


class ModelExtractor:
    """ëª¨ë¸ ë©”íƒ€ë°ì´í„° ì¶”ì¶œê¸°"""
    
    @staticmethod
    def extract_from_pytorch(file_path):
        """
        PyTorch ëª¨ë¸ (.pt, .pth) ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        
        Args:
            file_path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            dict: ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        try:
            import torch
            
            # CPUë¡œ ë¡œë“œ (ë©”ëª¨ë¦¬ ì ˆì•½)
            # ë¨¼ì € weights_only=Trueë¡œ ì‹œë„ (ì•ˆì „)
            try:
                checkpoint = torch.load(file_path, map_location='cpu', weights_only=True)
            except Exception:
                # weights_only=True ì‹¤íŒ¨ ì‹œ Falseë¡œ ì¬ì‹œë„
                # (YOLOv5 ë“± êµ¬ë²„ì „ ëª¨ë¸ í˜¸í™˜)
                try:
                    checkpoint = torch.load(file_path, map_location='cpu', weights_only=False)
                except Exception:
                    # ë‘˜ ë‹¤ ì‹¤íŒ¨í•˜ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‹œë„ (PyTorch 2.5 ì´í•˜)
                    checkpoint = torch.load(file_path, map_location='cpu')
            
            metadata = {
                'framework': 'PyTorch',
                'architecture': None,
                'classes': [],
                'num_classes': 0,
                'input_size': [],
                'model_type': None,
            }
            
            # ì²´í¬í¬ì¸íŠ¸ê°€ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš°
            if isinstance(checkpoint, dict):
                # YOLOv8 Ultralytics í˜•ì‹
                if 'model' in checkpoint:
                    model = checkpoint.get('model')
                    
                    # í´ë˜ìŠ¤ ì´ë¦„
                    if hasattr(model, 'names'):
                        metadata['classes'] = list(model.names.values())
                        metadata['num_classes'] = len(model.names)
                    
                    # ì•„í‚¤í…ì²˜
                    metadata['architecture'] = 'YOLOv8'
                    metadata['model_type'] = 'detection'
                    
                    # ì…ë ¥ í¬ê¸°
                    if hasattr(model, 'yaml'):
                        yaml_dict = model.yaml
                        if isinstance(yaml_dict, dict) and 'imgsz' in yaml_dict:
                            size = yaml_dict['imgsz']
                            if isinstance(size, int):
                                metadata['input_size'] = [size, size]
                            elif isinstance(size, (list, tuple)):
                                metadata['input_size'] = list(size)
                
                # YOLOv5 í˜•ì‹ (ë”•ì…”ë„ˆë¦¬ì— ì§ì ‘ ì •ë³´ê°€ ìˆìŒ)
                elif 'names' in checkpoint or 'nc' in checkpoint:
                    # í´ë˜ìŠ¤ ì •ë³´
                    if 'names' in checkpoint:
                        names = checkpoint['names']
                        if isinstance(names, dict):
                            metadata['classes'] = list(names.values())
                        elif isinstance(names, list):
                            metadata['classes'] = names
                        metadata['num_classes'] = len(metadata['classes'])
                    elif 'nc' in checkpoint:
                        metadata['num_classes'] = checkpoint['nc']
                    
                    # ì•„í‚¤í…ì²˜
                    metadata['architecture'] = 'YOLOv5'
                    metadata['model_type'] = 'detection'
                    
                    # ì…ë ¥ í¬ê¸° (ì¼ë°˜ì ìœ¼ë¡œ 640x640)
                    if 'imgsz' in checkpoint:
                        size = checkpoint['imgsz']
                        if isinstance(size, int):
                            metadata['input_size'] = [size, size]
                        elif isinstance(size, (list, tuple)):
                            metadata['input_size'] = list(size)
                    else:
                        metadata['input_size'] = [640, 640]  # ê¸°ë³¸ê°’
                
                # ì¼ë°˜ PyTorch ì²´í¬í¬ì¸íŠ¸
                else:
                    # í´ë˜ìŠ¤ ì •ë³´
                    if 'classes' in checkpoint:
                        metadata['classes'] = checkpoint['classes']
                        metadata['num_classes'] = len(checkpoint['classes'])
                    elif 'class_names' in checkpoint:
                        metadata['classes'] = checkpoint['class_names']
                        metadata['num_classes'] = len(checkpoint['class_names'])
                    
                    # ì•„í‚¤í…ì²˜ ì •ë³´
                    if 'arch' in checkpoint:
                        metadata['architecture'] = checkpoint['arch']
                    elif 'model_name' in checkpoint:
                        metadata['architecture'] = checkpoint['model_name']
            
            return metadata
            
        except ImportError as e:
            print(f'âš ï¸ PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}')
            return None
        except Exception as e:
            print(f'âŒ PyTorch ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}')
            import traceback
            traceback.print_exc()
            return None
    
    @staticmethod
    def extract_from_onnx(file_path):
        """
        ONNX ëª¨ë¸ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        
        Args:
            file_path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            dict: ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        try:
            import onnx
            
            model = onnx.load(file_path)
            
            metadata = {
                'framework': 'ONNX',
                'architecture': None,
                'classes': [],
                'num_classes': 0,
                'input_size': [],
            }
            
            # ì…ë ¥ í¬ê¸° ì¶”ì¶œ
            if model.graph.input:
                input_shape = model.graph.input[0].type.tensor_type.shape.dim
                metadata['input_size'] = [
                    d.dim_value for d in input_shape if d.dim_value > 0
                ]
            
            # ë©”íƒ€ë°ì´í„° í”„ë¡œí¼í‹°ì—ì„œ ì •ë³´ ì¶”ì¶œ
            for prop in model.metadata_props:
                if prop.key == 'classes' or prop.key == 'names':  # YOLOv5 ONNXëŠ” 'names' ì‚¬ìš©
                    # ë¬¸ìì—´ í˜•ì‹ í™•ì¸: "['fire', 'smoke']" ë˜ëŠ” "fire,smoke"
                    value = prop.value
                    if value.startswith('[') and value.endswith(']'):
                        # ['fire', 'smoke'] í˜•ì‹
                        import ast
                        try:
                            metadata['classes'] = ast.literal_eval(value)
                        except:
                            metadata['classes'] = value.strip('[]').replace("'", "").split(', ')
                    else:
                        # fire,smoke í˜•ì‹
                        metadata['classes'] = value.split(',')
                    metadata['num_classes'] = len(metadata['classes'])
                elif prop.key == 'architecture':
                    metadata['architecture'] = prop.value
                elif prop.key == 'model_type':
                    metadata['model_type'] = prop.value
            
            # ì¶œë ¥ ë ˆì´ì–´ì—ì„œ í´ë˜ìŠ¤ ê°œìˆ˜ ì¶”ì •
            if not metadata['num_classes'] and model.graph.output:
                for output in model.graph.output:
                    output_shape = output.type.tensor_type.shape.dim
                    if len(output_shape) > 0:
                        # ë§ˆì§€ë§‰ ì°¨ì›ì´ í´ë˜ìŠ¤ ê°œìˆ˜ì¼ ê°€ëŠ¥ì„±
                        last_dim = output_shape[-1].dim_value
                        if last_dim > 0 and last_dim < 10000:
                            metadata['num_classes'] = last_dim
                            break
            
            return metadata
            
        except ImportError:
            print('âš ï¸ ONNXê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
            return None
        except Exception as e:
            print(f'âŒ ONNX ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}')
            return None
    
    @staticmethod
    def extract_from_tensorflow(file_path):
        """
        TensorFlow/Keras ëª¨ë¸ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        
        Args:
            file_path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            dict: ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬
        """
        try:
            import tensorflow as tf
            
            metadata = {
                'framework': 'TensorFlow',
                'architecture': None,
                'classes': [],
                'num_classes': 0,
                'input_size': [],
            }
            
            # .h5 íŒŒì¼ (Keras)
            if file_path.endswith('.h5'):
                model = tf.keras.models.load_model(file_path, compile=False)
                
                # ì…ë ¥ í¬ê¸°
                if model.input_shape:
                    metadata['input_size'] = [
                        d for d in model.input_shape[1:] if d is not None
                    ]
                
                # ì¶œë ¥ í¬ê¸° (í´ë˜ìŠ¤ ê°œìˆ˜)
                if model.output_shape:
                    output_dim = model.output_shape[-1]
                    if output_dim:
                        metadata['num_classes'] = output_dim
            
            # SavedModel í˜•ì‹
            elif os.path.isdir(file_path):
                model = tf.saved_model.load(file_path)
                # TODO: SavedModel ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
            
            return metadata
            
        except ImportError:
            print('âš ï¸ TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
            return None
        except Exception as e:
            print(f'âŒ TensorFlow ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}')
            return None


def extract_metadata(model_instance):
    """
    Model ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ë° ì—…ë°ì´íŠ¸
    
    Args:
        model_instance: modelhub.models.Model ì¸ìŠ¤í„´ìŠ¤
    """
    if model_instance.source != 'upload' or not model_instance.model_file:
        print('âš ï¸ Upload ëª¨ë¸ì´ ì•„ë‹ˆê±°ë‚˜ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.')
        return
    
    file_path = model_instance.model_file.path
    if not os.path.exists(file_path):
        print(f'âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}')
        return
    
    file_ext = Path(file_path).suffix.lower()
    
    extractor = ModelExtractor()
    metadata = None
    
    # íŒŒì¼ í˜•ì‹ë³„ ì¶”ì¶œ
    if file_ext in ['.pt', '.pth']:
        print(f'ğŸ” PyTorch ëª¨ë¸ ë¶„ì„ ì¤‘: {file_path}')
        metadata = extractor.extract_from_pytorch(file_path)
    
    elif file_ext == '.onnx':
        print(f'ğŸ” ONNX ëª¨ë¸ ë¶„ì„ ì¤‘: {file_path}')
        metadata = extractor.extract_from_onnx(file_path)
    
    elif file_ext in ['.h5', '.pb']:
        print(f'ğŸ” TensorFlow ëª¨ë¸ ë¶„ì„ ì¤‘: {file_path}')
        metadata = extractor.extract_from_tensorflow(file_path)
    
    else:
        print(f'âš ï¸ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_ext}')
        return
    
    # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
    if metadata:
        print(f'âœ… ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì„±ê³µ')
        
        if metadata.get('framework'):
            model_instance.framework = metadata['framework']
        
        if metadata.get('architecture'):
            model_instance.architecture = metadata['architecture']
        
        if metadata.get('classes'):
            model_instance.classes = metadata['classes']
            model_instance.num_classes = len(metadata['classes'])
        elif metadata.get('num_classes'):
            model_instance.num_classes = metadata['num_classes']
        
        if metadata.get('input_size'):
            model_instance.input_size = metadata['input_size']
        
        # Task type ì¶”ë¡  (ì‚¬ìš©ìê°€ ì„ íƒí•˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì¶”ì²œ)
        if not model_instance.task_type:
            recommended_task = None
            
            # 1. ëª…ì‹œì  model_typeì´ ìˆìœ¼ë©´ ì‚¬ìš©
            if metadata.get('model_type') == 'detection':
                recommended_task = 'object_detection'
            # 2. YOLO ê³„ì—´ì€ ë¬´ì¡°ê±´ ê°ì²´ íƒì§€
            elif 'yolo' in str(metadata.get('architecture', '')).lower():
                recommended_task = 'object_detection'
            # 3. ONNX íŒŒì¼ì—ì„œ 'names' ë©”íƒ€ë°ì´í„°ê°€ ìˆìœ¼ë©´ ê°ì²´ íƒì§€ (YOLOv5 ONNX)
            elif metadata.get('framework') == 'ONNX' and metadata.get('classes'):
                recommended_task = 'object_detection'
            # 4. í´ë˜ìŠ¤ê°€ 1000ê°œ ì´ìƒì´ë©´ ë¶„ë¥˜
            elif metadata.get('num_classes') and metadata['num_classes'] >= 1000:
                recommended_task = 'image_classification'
            # 5. ê¸°ë³¸ ì¶”ì²œê°’ì€ ê°ì²´ íƒì§€
            else:
                recommended_task = 'object_detection'
            
            # ì¶”ì²œëœ task_type ì„¤ì •
            model_instance.task_type = recommended_task
            print(f'ğŸ’¡ ì¶”ì²œ Task Type: {recommended_task} (ì‚¬ìš©ìê°€ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤)')
        
        model_instance.save()
        
        print(f'ğŸ“Š ì¶”ì¶œëœ ì •ë³´:')
        print(f'  - Framework: {model_instance.framework}')
        print(f'  - Architecture: {model_instance.architecture}')
        print(f'  - Classes: {model_instance.num_classes}ê°œ')
        print(f'  - Input Size: {model_instance.input_size}')
        print(f'  - Task Type: {model_instance.task_type}')
    else:
        print(f'âŒ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨')


# í¸ì˜ í•¨ìˆ˜
def extract_pytorch_classes(file_path):
    """PyTorch ëª¨ë¸ì—ì„œ í´ë˜ìŠ¤ ëª©ë¡ë§Œ ì¶”ì¶œ"""
    metadata = ModelExtractor.extract_from_pytorch(file_path)
    return metadata.get('classes', []) if metadata else []


def extract_onnx_input_size(file_path):
    """ONNX ëª¨ë¸ì—ì„œ ì…ë ¥ í¬ê¸°ë§Œ ì¶”ì¶œ"""
    metadata = ModelExtractor.extract_from_onnx(file_path)
    return metadata.get('input_size', []) if metadata else []